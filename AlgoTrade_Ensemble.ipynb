{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlgoTrade_Ensemble.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1whelavoovieU9BDCYlZHN45JLgDHoeRn",
      "authorship_tag": "ABX9TyOHGqldufOgVGycEQv4TdDb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evalucre/Economic-Financial-Analysis/blob/main/AlgoTrade_Ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKQI6p2Pi-5O",
        "outputId": "e5b8fa47-c533-4286-d609-8544bd34cb3d"
      },
      "source": [
        "!pip install yahoofinancials\n",
        "\n",
        "!pip install yahoo_fin\n",
        "!pip install requests_html\n",
        "\n",
        "!pip install yfinance \n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import os \n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objs as go\n",
        "import pandas as pd\n",
        "import datetime as datetime\n",
        "from yahoofinancials import YahooFinancials\n",
        "import yahoo_fin.stock_info as si\n",
        "import yfinance as yf\n",
        "\n",
        "import requests\n",
        "from math import floor\n",
        "from termcolor import colored as cl\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (20, 10)\n",
        "plt.style.use('fivethirtyeight')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting yahoofinancials\n",
            "  Downloading https://files.pythonhosted.org/packages/97/fe/be0f6ea704137848779fc61e7d1c9a901489aaf3423cd7b6f86a350c14c6/yahoofinancials-1.6.tar.gz\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from yahoofinancials) (4.6.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from yahoofinancials) (2018.9)\n",
            "Building wheels for collected packages: yahoofinancials\n",
            "  Building wheel for yahoofinancials (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yahoofinancials: filename=yahoofinancials-1.6-cp37-none-any.whl size=15192 sha256=437ac1b45110cea24f6c2587224b9d90ae86a728b5f14ecf7caca0cd94586252\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/7e/cf/4977a8572d5247242a4b13018d1d36923024ba84236e0d28bc\n",
            "Successfully built yahoofinancials\n",
            "Installing collected packages: yahoofinancials\n",
            "Successfully installed yahoofinancials-1.6\n",
            "Collecting yahoo_fin\n",
            "  Downloading https://files.pythonhosted.org/packages/b4/48/22c861ad5328b66aed12818901c2c2bd908f01a3de2b651d6f7ef05abd52/yahoo_fin-0.8.8-py3-none-any.whl\n",
            "Collecting feedparser\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/21/faf1bac028662cc8adb2b5ef7a6f3999a765baa2835331df365289b0ca56/feedparser-6.0.2-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 2.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from yahoo_fin) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from yahoo_fin) (1.1.5)\n",
            "Collecting requests-html\n",
            "  Downloading https://files.pythonhosted.org/packages/24/bc/a4380f09bab3a776182578ce6b2771e57259d0d4dbce178205779abdc347/requests_html-0.10.0-py3-none-any.whl\n",
            "Collecting sgmllib3k\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/bd/3704a8c3e0942d711c1299ebf7b9091930adae6675d7c8f476a7ce48653c/sgmllib3k-1.0.0.tar.gz\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo_fin) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo_fin) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo_fin) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo_fin) (2.10)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->yahoo_fin) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->yahoo_fin) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->yahoo_fin) (2018.9)\n",
            "Collecting w3lib\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/59/b6b14521090e7f42669cafdb84b0ab89301a42f1f1a82fcf5856661ea3a7/w3lib-1.22.0-py2.py3-none-any.whl\n",
            "Collecting pyquery\n",
            "  Downloading https://files.pythonhosted.org/packages/58/0b/85d15e21f660a8ea68b1e0286168938857391f4ec9f6d204d91c9e013826/pyquery-1.4.3-py3-none-any.whl\n",
            "Collecting parse\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a1/82ce536be577ba09d4dcee45db58423a180873ad38a2d014d26ab7b7cb8a/parse-1.19.0.tar.gz\n",
            "Collecting pyppeteer>=0.0.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/05/ea3250282e46fda60df1f1d5246bb8cdc022abb89969c61a98ea28fd6b82/pyppeteer-0.2.5-py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 6.2MB/s \n",
            "\u001b[?25hCollecting fake-useragent\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/79/af647635d6968e2deb57a208d309f6069d31cb138066d7e821e575112a80/fake-useragent-0.1.11.tar.gz\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from requests-html->yahoo_fin) (0.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->yahoo_fin) (1.15.0)\n",
            "Collecting cssselect>0.7.9\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests-html->yahoo_fin) (4.2.6)\n",
            "Collecting importlib-metadata<3.0.0,>=2.1.1; python_version < \"3.8\"\n",
            "  Downloading https://files.pythonhosted.org/packages/98/b8/8ec57a8ef46fbe7f185318c7ff7df9a06c9df451d9a59a067bfa851bb828/importlib_metadata-2.1.1-py2.py3-none-any.whl\n",
            "Collecting websockets<9.0,>=8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/0b/3ebc752392a368af14dd24ee041683416ac6d2463eead94b311b11e41c82/websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.8MB/s \n",
            "\u001b[?25hCollecting tqdm<5.0.0,>=4.42.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/d7/f357d98e9b50346bcb6095fe3ad205d8db3174eb5edb03edfe7c4099576d/tqdm-4.61.0-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (1.4.4)\n",
            "Collecting pyee<9.0.0,>=8.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0d/0a/933b3931107e1da186963fd9bb9bceb9a613cff034cb0fb3b0c61003f357/pyee-8.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->requests-html->yahoo_fin) (4.6.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<3.0.0,>=2.1.1; python_version < \"3.8\"->pyppeteer>=0.0.14->requests-html->yahoo_fin) (3.4.1)\n",
            "Building wheels for collected packages: sgmllib3k, parse, fake-useragent\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-cp37-none-any.whl size=6067 sha256=db7ad73ba7c86f6fe9ad7ab754b1407a3359c686bd3c7dbd1bcb2d687c601dc4\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/80/5a/444ba08a550cdd241bd9baf8bae44be750efe370adb944506a\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parse: filename=parse-1.19.0-cp37-none-any.whl size=24581 sha256=de91d72c53c4588ad30c29d2726be7ecd2f8b5d70c55b82bb6e26392888cc59f\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/39/ea/e2fd678bd130953f5438470b8dfa529f00787e9b8b92b27467\n",
            "  Building wheel for fake-useragent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-cp37-none-any.whl size=13485 sha256=cb4dc1f57365cd9e8c981c46b47b545e625d4d2f8cf1e8b7232901a5291bf76b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/63/09/d1dc15179f175357d3f5c00cbffbac37f9e8690d80545143ff\n",
            "Successfully built sgmllib3k parse fake-useragent\n",
            "\u001b[31mERROR: pyppeteer 0.2.5 has requirement urllib3<2.0.0,>=1.25.8, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sgmllib3k, feedparser, w3lib, cssselect, pyquery, parse, importlib-metadata, websockets, tqdm, pyee, pyppeteer, fake-useragent, requests-html, yahoo-fin\n",
            "  Found existing installation: importlib-metadata 4.0.1\n",
            "    Uninstalling importlib-metadata-4.0.1:\n",
            "      Successfully uninstalled importlib-metadata-4.0.1\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed cssselect-1.1.0 fake-useragent-0.1.11 feedparser-6.0.2 importlib-metadata-2.1.1 parse-1.19.0 pyee-8.1.0 pyppeteer-0.2.5 pyquery-1.4.3 requests-html-0.10.0 sgmllib3k-1.0.0 tqdm-4.61.0 w3lib-1.22.0 websockets-8.1 yahoo-fin-0.8.8\n",
            "Requirement already satisfied: requests_html in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: w3lib in /usr/local/lib/python3.7/dist-packages (from requests_html) (1.22.0)\n",
            "Requirement already satisfied: pyppeteer>=0.0.14 in /usr/local/lib/python3.7/dist-packages (from requests_html) (0.2.5)\n",
            "Requirement already satisfied: pyquery in /usr/local/lib/python3.7/dist-packages (from requests_html) (1.4.3)\n",
            "Requirement already satisfied: parse in /usr/local/lib/python3.7/dist-packages (from requests_html) (1.19.0)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.7/dist-packages (from requests_html) (0.1.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from requests_html) (2.23.0)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from requests_html) (0.0.1)\n",
            "Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from w3lib->requests_html) (1.15.0)\n",
            "Collecting urllib3<2.0.0,>=1.25.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/cd/1e2ec680ec7b09846dc6e605f5a7709dfb9d7128e51a026e7154e18a234e/urllib3-1.26.5-py2.py3-none-any.whl (138kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata<3.0.0,>=2.1.1; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests_html) (2.1.1)\n",
            "Requirement already satisfied: pyee<9.0.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests_html) (8.1.0)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests_html) (1.4.4)\n",
            "Requirement already satisfied: websockets<9.0,>=8.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests_html) (8.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests_html) (4.61.0)\n",
            "Requirement already satisfied: cssselect>0.7.9 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests_html) (1.1.0)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests_html) (4.2.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->requests_html) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->requests_html) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->requests_html) (2020.12.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->requests_html) (4.6.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<3.0.0,>=2.1.1; python_version < \"3.8\"->pyppeteer>=0.0.14->requests_html) (3.4.1)\n",
            "\u001b[31mERROR: requests 2.23.0 has requirement urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you'll have urllib3 1.26.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: urllib3\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed urllib3-1.26.5\n",
            "Collecting yfinance\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/ee/315752b9ef281ba83c62aa7ec2e2074f85223da6e7e74efb4d3e11c0f510/yfinance-0.1.59.tar.gz\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.9)\n",
            "Collecting lxml>=4.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/c0/d0526314971fc661b083ab135747dc68446a3022686da8c16d25fcf6ef07/lxml-4.6.3-cp37-cp37m-manylinux2014_x86_64.whl (6.3MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3MB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/aa/4ef5aa67a9a62505db124a5cb5262332d1d4153462eb8fd89c9fa41e5d92/urllib3-1.25.11-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 38.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
            "Building wheels for collected packages: yfinance\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.59-py2.py3-none-any.whl size=23442 sha256=906624e05d0d60053a3a714c0a5546d6f883c0be88e888ebd5d652170936b517\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/2a/0f/4b5a86e1d52e451757eb6bc17fd899629f0925c777741b6d04\n",
            "Successfully built yfinance\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: lxml, yfinance, urllib3\n",
            "  Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "  Found existing installation: urllib3 1.26.5\n",
            "    Uninstalling urllib3-1.26.5:\n",
            "      Successfully uninstalled urllib3-1.26.5\n",
            "Successfully installed lxml-4.6.3 urllib3-1.25.11 yfinance-0.1.59\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmhgf3r-X13V"
      },
      "source": [
        "def get_ticker_list(grouped_stocks):\n",
        "  if grouped_stocks == 'dow':\n",
        "    ticker_list = si.tickers_dow()\n",
        "\n",
        "  elif  grouped_stocks == 'sp500':\n",
        "    ticker_list = si.tickers_sp500()\n",
        "\n",
        "  elif grouped_stocks == 'nasdaq':\n",
        "    ticker_list = si.tickers_nasdaq()\n",
        "\n",
        "  elif grouped_stocks == 'tsx':\n",
        "    ticker_list = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/tsx_tickers.csv')\n",
        "    ticker_list = ticker_list.iloc[:,0].tolist()\n",
        "\n",
        "  elif grouped_stocks == 'exp':\n",
        "    ticker_list = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/exp_tickers.csv')  \n",
        "    ticker_list = ticker_list.iloc[:,0].tolist()  \n",
        "\n",
        "  elif grouped_stocks == 'tsx60':\n",
        "    ticker_list = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/tsx60_tickers.csv')  \n",
        "    ticker_list = ticker_list.iloc[:,0].tolist()  \n",
        "\n",
        "  else:\n",
        "    ticker_list = \"Input group of stocks not recognised\"\n",
        "\n",
        "  return ticker_list\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewiDsmXUeHCs"
      },
      "source": [
        "def get_trading_data(ticker_list, start_date, end_date, index_as_date, interval):\n",
        "  \n",
        "  trading_datas = {}\n",
        "  \n",
        "  for ticker in ticker_list:\n",
        "    try:\n",
        "      trading_datas[ticker] = si.get_data(ticker, start_date, end_date, index_as_date, interval)  \n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  trading_datas = pd.concat(trading_datas)\n",
        "\n",
        "  trading_datas = trading_datas.reset_index(level=[0,1])\\\n",
        "                               .drop(labels='level_0', axis=1)\\\n",
        "                               .rename(columns={'level_1':'date'})\\\n",
        "                               .set_index('date')\n",
        "\n",
        "  return trading_datas  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztxE4tz798LC"
      },
      "source": [
        "def get_financial_data(ticker_list):\n",
        "  \n",
        "  cashflow_datas = {}\n",
        "  balncsheet_datas = {}\n",
        "  incomstment_datas = {}\n",
        "  \n",
        "  for ticker in ticker_list:\n",
        "    cashflow_datas[ticker] = si.get_cash_flow(ticker) \n",
        "    balncsheet_datas[ticker] = si.get_balance_sheet(ticker)\n",
        "    incomstment_datas[ticker] = si.get_income_statement(ticker) \n",
        "\n",
        "\n",
        "  cashflow_datas = pd.concat(cashflow_datas) \n",
        "  balncsheet_datas = pd.concat(balncsheet_datas)\n",
        "  incomstment_datas = pd.concat(incomstment_datas)\n",
        "\n",
        "  cashflow_datas = cashflow_datas.transpose()\n",
        "  balncsheet_datas = balncsheet_datas.transpose()\n",
        "  incomstment_datas = incomstment_datas.transpose()\n",
        "\n",
        "  return cashflow_datas, balncsheet_datas, incomstment_datas \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFV7I9vW3NYf"
      },
      "source": [
        "def get_selection(trading_datas):\n",
        "  \"\"\"\n",
        "  Select best stocks (numb = 10) with right price volatility and variability for trading \n",
        "  or investing. When the preference is to identify stocks for investing, input \n",
        "  data should cover a longer time period (years). When trading is the focus, the\n",
        "  input data should cover shorter time periods (like week, month, or quarters) \n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  metric_Pstdv = {}\n",
        "  metric_Rstdv = {}\n",
        "  metric_Vmean = {}\n",
        "  metric_Msize = {}\n",
        "\n",
        "  trading_datas['prange'] = trading_datas['high'] - trading_datas['low']\n",
        "\n",
        "  stocks = trading_datas.ticker.unique()\n",
        "  for stock in stocks:\n",
        "    dt = trading_datas.loc[(trading_datas.ticker == stock)]\n",
        "    metric_Pstdv[stock] = dt.close.std()  #price standard deviation (high for investment stocks) - profitability indicator\n",
        "    metric_Rstdv[stock] = dt.prange.std()  #prange standard deviation (high for trading stocks) - volatility indicator\n",
        "    metric_Vmean[stock] = dt.volume.mean()  #mean of volume - liquidity indicator\n",
        "    metric_Msize[stock] = (dt.volume.mean())*(dt.close.mean())  #measure of market size/capitalization\n",
        "\n",
        "#Rank stocks using calculated metrics\n",
        "  metric_Pstdv = pd.DataFrame(metric_Pstdv, index=[0])\n",
        "  metric_Rstdv = pd.DataFrame(metric_Rstdv, index=[0])\n",
        "  metric_Vmean = pd.DataFrame(metric_Vmean, index=[0])\n",
        "  metric_Msize = pd.DataFrame(metric_Msize, index=[0])\n",
        "\n",
        "  metric_Pstdv = metric_Pstdv.T.reset_index()\\\n",
        "                               .rename(columns={'index':'ticker'})\\\n",
        "                               .rename(columns={0:'Pstdv'})\\\n",
        "                               .sort_values(by=['Pstdv'], ascending = False)\n",
        "                            \n",
        "  \n",
        "  metric_Rstdv = metric_Rstdv.T.reset_index()\\\n",
        "                               .rename(columns={'index':'ticker'})\\\n",
        "                               .rename(columns={0:'Rstdv'})\\\n",
        "                               .sort_values(by=['Rstdv'], ascending = False)\n",
        " \n",
        "\n",
        "  metric_Vmean = metric_Vmean.T.reset_index()\\\n",
        "                               .rename(columns={'index':'ticker'})\\\n",
        "                               .rename(columns={0:'Vmean'})\\\n",
        "                               .sort_values(by=['Vmean'], ascending = False)\n",
        "\n",
        "\n",
        "  metric_Msize = metric_Msize.T.reset_index()\\\n",
        "                               .rename(columns={'index':'ticker'})\\\n",
        "                               .rename(columns={0:'Msize'})\\\n",
        "                               .sort_values(by=['Msize'], ascending = False)\n",
        "                          \n",
        "#Select top 10 stocks with highest values of the metrics\n",
        "  numb = 50\n",
        "  metric_Pstdv = metric_Pstdv[:numb]['ticker'].reset_index(drop=True)      \n",
        "  metric_Rstdv = metric_Rstdv[:numb]['ticker'].reset_index(drop=True)\n",
        "  metric_Vmean = metric_Vmean[:numb]['ticker'].reset_index(drop=True)\n",
        "  metric_Msize = metric_Msize[:numb]['ticker'].reset_index(drop=True) \n",
        "\n",
        "  volatl_select = metric_Rstdv\n",
        "\n",
        "  tradin_select = metric_Rstdv[(pd.Series(metric_Rstdv.to_numpy()).isin(metric_Vmean.to_numpy()))]\n",
        "  invest_select = metric_Pstdv[(pd.Series(metric_Pstdv.to_numpy()).isin(metric_Vmean.to_numpy()))]\n",
        "  \n",
        "  #Definitions:\n",
        "  #tradin_select - combines volatility and high trade volumes\n",
        "  #invest_select - long term growth and high capitalization\n",
        "  #volatl_select - high volatility but does not necessarily have trade volumes\n",
        "\n",
        "  return tradin_select, invest_select, volatl_select\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugDJgpsgtB8a"
      },
      "source": [
        "def get_macd(trading_datas, select_ticker, fastm, slowm, smooth):\n",
        "\n",
        "  df = trading_datas[trading_datas['ticker'] == select_ticker]\n",
        "\n",
        "  exp1 = df.close.ewm(span=fastm, adjust=False).mean()\n",
        "  exp2 = df.close.ewm(span=slowm, adjust=False).mean()\n",
        "  macd = pd.DataFrame(exp1 - exp2).rename(columns = {'close':'macd'})\n",
        "  signal = pd.DataFrame(macd.ewm(span = smooth, adjust = False).mean()).rename(columns = {'macd':'signal'})\n",
        "  hist = pd.DataFrame(macd['macd'] - signal['signal']).rename(columns = {0:'hist'})\n",
        "  \n",
        "  df = pd.concat([df, macd, signal, hist], join = 'inner', axis = 1)\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svCrlo41EBdJ"
      },
      "source": [
        "def get_smap(trading_datas, select_ticker, roll_wks1, roll_wks2, roll_wks10, roll_wks30, roll_wks40):\n",
        "\n",
        "  df = trading_datas[trading_datas['ticker'] == select_ticker]\n",
        "\n",
        "  smap_wks1 = df.close.rolling(window=roll_wks1).mean()\n",
        "  smap_wks1 = pd.DataFrame(smap_wks1).rename(columns = {'close':'smap_wks1'})\n",
        "\n",
        "  smap_wks2 = df.close.rolling(window=roll_wks2).mean()\n",
        "  smap_wks2 = pd.DataFrame(smap_wks2).rename(columns = {'close':'smap_wks2'})\n",
        "\n",
        "  smap_wks10 = df.close.rolling(window=roll_wks10).mean()\n",
        "  smap_wks10 = pd.DataFrame(smap_wks10).rename(columns = {'close':'smap_wks10'})\n",
        "\n",
        "  smap_wks30 = df.close.rolling(window=roll_wks30).mean()\n",
        "  smap_wks30 = pd.DataFrame(smap_wks30).rename(columns = {'close':'smap_wks30'})\n",
        "\n",
        "  smap_wks40 = df.close.rolling(window=roll_wks40).mean()\n",
        "  smap_wks40 = pd.DataFrame(smap_wks40).rename(columns = {'close':'smap_wks40'})\n",
        "\n",
        "  df = pd.concat([df, smap_wks1, smap_wks2, smap_wks10, smap_wks30, smap_wks40], join = 'inner', axis = 1)\n",
        "  \n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGTvgg7bGa_T"
      },
      "source": [
        "def get_smav(trading_datas, select_ticker, roll_wks1, roll_wks2, roll_wks10, roll_wks30, roll_wks40):\n",
        "\n",
        "  df = trading_datas[trading_datas['ticker'] == select_ticker]\n",
        "\n",
        "  smav_wks1 = df.volume.rolling(window=roll_wks1).mean()\n",
        "  smav_wks1 = pd.DataFrame(smav_wks1).rename(columns = {'volume':'smav_wks1'})\n",
        "\n",
        "  smav_wks2 = df.volume.rolling(window=roll_wks2).mean()\n",
        "  smav_wks2 = pd.DataFrame(smav_wks2).rename(columns = {'volume':'smav_wks2'})\n",
        "\n",
        "  smav_wks10 = df.volume.rolling(window=roll_wks10).mean()\n",
        "  smav_wks10 = pd.DataFrame(smav_wks10).rename(columns = {'volume':'smav_wks10'})\n",
        "\n",
        "  smav_wks30 = df.volume.rolling(window=roll_wks30).mean()\n",
        "  smav_wks30 = pd.DataFrame(smav_wks30).rename(columns = {'volume':'smav_wks30'})\n",
        "\n",
        "  smav_wks40 = df.volume.rolling(window=roll_wks40).mean()\n",
        "  smav_wks40 = pd.DataFrame(smav_wks40).rename(columns = {'volume':'smav_wks40'})\n",
        "\n",
        "  df = pd.concat([df, smav_wks1, smav_wks2, smav_wks10, smav_wks30, smav_wks40], join = 'inner', axis = 1)\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVVNjrClOYWV"
      },
      "source": [
        " def get_stochst(trading_datas, select_ticker, roll_low, roll_high, fasts, slows):\n",
        "    \"\"\"\n",
        "    Fast stochastic calculation\n",
        "    %K = (Current Close - Lowest Low)/\n",
        "    (Highest High - Lowest Low) * 100\n",
        "    %D = SMA of %K\n",
        "\n",
        "    Slow stochastic calculation\n",
        "    %K = %D of fast stochastic\n",
        "    %D = SMA of %K\n",
        "\n",
        "    When %K crosses above %D, buy signal \n",
        "    When the %K crosses below %D, sell signal\n",
        "    \"\"\"\n",
        "# It seems like d_fast would be best for high volatility trading and d_slow for lower volatility investing\n",
        "\n",
        "    df = trading_datas[trading_datas['ticker'] == select_ticker]\n",
        "\n",
        "# Set minimum low and maximum high of the k stoch\n",
        "    low_min  = df.low.rolling( window = roll_low ).min()\n",
        "    high_max = df.high.rolling( window = roll_high ).max()\n",
        "\n",
        "# Fast Stochastic\n",
        "    df['k_fast'] = 100 * (df.close - low_min)/(high_max - low_min)\n",
        "    df['d_fast'] = df['k_fast'].rolling(window = fasts).mean()\n",
        "\n",
        "# Slow Stochastic\n",
        "    df['k_slow'] = df['d_fast']\n",
        "    df['d_slow'] = df['k_slow'].rolling(window = slows).mean()\n",
        "\n",
        "    return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-VgcWpXfDaL"
      },
      "source": [
        "def get_boband(trading_datas, select_ticker, roll_period):\n",
        "#Bollinger Band Algorithm: it seems this is designed for live market decision-making\n",
        "#The rolling period can be the last 20 trading periods\n",
        "\n",
        "  df = trading_datas[trading_datas['ticker'] == select_ticker]\n",
        "\n",
        "  df['Mband'] = df['close'].rolling(window = roll_period).mean()                       #middle band\n",
        "  df['Uband'] = df['Mband'] + 1.96*df['close'].rolling(window = roll_period).std()     #upper band\n",
        "  df['Lband'] = df['Mband'] - 1.96*df['close'].rolling(window = roll_period).std()     #lower band\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLMJKmIw1dqR"
      },
      "source": [
        "def strategy_macd(macd_data):    \n",
        "    buy_price = []\n",
        "    sell_price = []\n",
        "    macd_signal = []\n",
        "    position = np.zeros(len(macd_data))\n",
        "    signal = 0\n",
        "\n",
        "    for i in range(len(macd_data)):\n",
        "        if macd_data['macd'][i] > macd_data['signal'][i]:\n",
        "            if signal != 1:\n",
        "                buy_price.append(macd_data['close'][i])\n",
        "                sell_price.append(np.nan)\n",
        "                signal = 1\n",
        "                macd_signal.append(signal)\n",
        "            else:\n",
        "                buy_price.append(np.nan)\n",
        "                sell_price.append(np.nan)\n",
        "                macd_signal.append(0)\n",
        "        elif macd_data['macd'][i] < macd_data['signal'][i]:\n",
        "            if signal != -1:\n",
        "                buy_price.append(np.nan)\n",
        "                sell_price.append(macd_data['close'][i])\n",
        "                signal = -1\n",
        "                macd_signal.append(signal)\n",
        "            else:\n",
        "                buy_price.append(np.nan)\n",
        "                sell_price.append(np.nan)\n",
        "                macd_signal.append(0)\n",
        "        else:\n",
        "            buy_price.append(np.nan)\n",
        "            sell_price.append(np.nan)\n",
        "            macd_signal.append(0)\n",
        "\n",
        "    for i in range(len(macd_data)):\n",
        "      if macd_signal[i] == 1:\n",
        "        position[i] = 1\n",
        "      elif macd_signal[i] == -1:\n",
        "        position[i] = 0\n",
        "      elif (macd_signal[i] == 0) and (i == 0):\n",
        "        position[i] = 0\n",
        "      else:\n",
        "        position[i] = position[i-1]\n",
        "\n",
        "    macd_signal = pd.DataFrame(macd_signal).rename(columns = {0:'macd_signal'}).set_index(macd_data.index)\n",
        "    position = pd.DataFrame(position).rename(columns = {0:'macd_position'}).set_index(macd_data.index)\n",
        "    buy_price = pd.DataFrame(buy_price).rename(columns = {0:'buy_price'}).set_index(macd_data.index)\n",
        "    sell_price = pd.DataFrame(sell_price).rename(columns = {0:'sell_price'}).set_index(macd_data.index)\n",
        "\n",
        "    macd_decisions = pd.concat([macd_data['close'], macd_data['macd'], macd_data['signal'], macd_signal, position, buy_price, sell_price], join = 'inner', axis = 1)\n",
        "\n",
        "\n",
        "    return macd_decisions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7opKc0BKCvD"
      },
      "source": [
        "def strategy_smap(smap_data):    \n",
        "    buy_price = []\n",
        "    sell_price = []\n",
        "    smap_signal = []\n",
        "    position = np.zeros(len(smap_data))\n",
        "    signal1, signal2, signal3, signal4, signal5, signal6, signal7, signal8 = [], [], [], [], [], [], [], []\n",
        "    \n",
        "#Stock price is above both the 150-day (30-week) and the 200-day (40-week) moving average price lines.   \n",
        "    signal = 0\n",
        "    for i in range(len(smap_data)):\n",
        "        if (smap_data['close'][i] > smap_data['smap_wks30'][i]) and (smap_data['close'][i] > smap_data['smap_wks40'][i]):\n",
        "            if signal != 1:\n",
        "                signal = 1\n",
        "                signal1.append(signal)\n",
        "            else:\n",
        "                signal1.append(0)\n",
        "        elif (smap_data['close'][i] < smap_data['smap_wks30'][i]) and (smap_data['close'][i] < smap_data['smap_wks40'][i]):\n",
        "            if signal != -1:\n",
        "                signal = -1\n",
        "                signal1.append(signal)\n",
        "            else:\n",
        "                signal1.append(0)\n",
        "        else:\n",
        "            signal1.append(0)\n",
        "\n",
        "#The 150-day moving average is above the 200-day moving average.\n",
        "    signal = 0\n",
        "    for i in range(len(smap_data)):\n",
        "        if smap_data['smap_wks30'][i] > smap_data['smap_wks40'][i]:\n",
        "            if signal != 1:\n",
        "                signal = 1\n",
        "                signal2.append(signal)\n",
        "            else:\n",
        "                signal2.append(0)\n",
        "        elif smap_data['smap_wks30'][i] < smap_data['smap_wks40'][i]:\n",
        "            if signal != -1:\n",
        "                signal = -1\n",
        "                signal2.append(signal)\n",
        "            else:\n",
        "                signal2.append(0)\n",
        "        else:\n",
        "            signal2.append(0)\n",
        "\n",
        "#The 200-day moving average line is trending up for at least 1-month (preferably 4 to 5 months or longer).\n",
        "    signal = 0\n",
        "    smooth = 20    #smooth specifies the period over which trend is calculated - we are using 1 month (4 weeks) as default\n",
        "    trend_wks40 = smap_data.smap_wks40.rolling(window=smooth).mean()\n",
        "    trend_wks40 = pd.DataFrame(trend_wks40).rename(columns = {'smap_wks40':'trend_wks40'})\n",
        "    smap_data = pd.concat([smap_data, trend_wks40], join = 'inner', axis = 1)\n",
        "    signal3.append(0)   #signal3[0] = 0\n",
        "    for i in range(1, len(smap_data)):\n",
        "        if (smap_data['trend_wks40'][i] - smap_data['trend_wks40'][i-1]) > 0:\n",
        "            if signal != 1:\n",
        "                signal = 1\n",
        "                signal3.append(signal)\n",
        "            else:\n",
        "                signal3.append(0)\n",
        "        elif (smap_data['trend_wks40'][i] - smap_data['trend_wks40'][i-1]) < 0:\n",
        "            if signal != -1:\n",
        "                signal = -1\n",
        "                signal3.append(signal)\n",
        "            else:\n",
        "                signal3.append(0)\n",
        "        else:\n",
        "            signal3.append(0)\n",
        "\n",
        "#The 50-day (10-week moving average) is above both the 150-day and the 200-day moving averages.\n",
        "    signal = 0\n",
        "    for i in range(len(smap_data)):\n",
        "        if (smap_data['smap_wks10'][i] > smap_data['smap_wks30'][i]) and (smap_data['smap_wks10'][i] > smap_data['smap_wks40'][i]):\n",
        "            if signal != 1:\n",
        "                signal = 1\n",
        "                signal4.append(signal)\n",
        "            else:\n",
        "                signal4.append(0)\n",
        "        elif (smap_data['smap_wks10'][i] < smap_data['smap_wks30'][i]) and (smap_data['smap_wks10'][i] < smap_data['smap_wks40'][i]):\n",
        "            if signal != -1:\n",
        "                signal = -1\n",
        "                signal4.append(signal)\n",
        "            else:\n",
        "                signal4.append(0)\n",
        "        else:\n",
        "            signal4.append(0)\n",
        "\n",
        "#The current stock price is at least 25 percent above its 52-week low. (Many of the best selections will be 100 percent, 300 percent, or more above their 52-week consolidation period and mount a large-scale advance).\n",
        "    signal = 0\n",
        "    min_wks52 = smap_data['close'].min()   #I decided not to specify 52 week minimum since this would be run for various periods, if not this would be a NA when the data is less than 52 weeks\n",
        "    min_band = 1.25*min_wks52\n",
        "    for i in range(len(smap_data)):\n",
        "        if smap_data['close'][i] >= min_band:\n",
        "            if signal != 1:\n",
        "                signal = 1\n",
        "                signal5.append(signal)\n",
        "            else:\n",
        "                signal5.append(0)\n",
        "        elif smap_data['close'][i] < min_band:\n",
        "            if signal != -1:\n",
        "                signal = -1\n",
        "                signal5.append(signal)\n",
        "            else:\n",
        "                signal5.append(0)\n",
        "        else:\n",
        "            signal5.append(0)\n",
        "\n",
        "#The current stock price is within at least 25 percent of its 52-week high (the closer to a new high the better).\n",
        "    signal = 0\n",
        "    max_wks52 = smap_data['close'].max()   #I decided not to specify 52 week maximum since this would be run for various periods, if not this would be a NA when the data is less than 52 weeks\n",
        "    max_band = 0.75*max_wks52\n",
        "    for i in range(len(smap_data)):\n",
        "        if smap_data['close'][i] >= max_band:\n",
        "            if signal != 1:\n",
        "                signal = 1\n",
        "                signal6.append(signal)\n",
        "            else:\n",
        "                signal6.append(0)\n",
        "        elif smap_data['close'][i] < max_band:\n",
        "            if signal != -1:\n",
        "                signal = -1\n",
        "                signal6.append(signal)\n",
        "            else:\n",
        "                signal6.append(0)\n",
        "        else:\n",
        "            signal6.append(0)\n",
        "\n",
        "#The current price is trading above the 50-day moving average as the stock is coming out of a base\n",
        "    signal = 0\n",
        "    for i in range(len(smap_data)):\n",
        "        if smap_data['close'][i] > smap_data['smap_wks10'][i]:\n",
        "            if signal != 1:\n",
        "                signal = 1\n",
        "                signal7.append(signal)\n",
        "            else:\n",
        "                signal7.append(0)\n",
        "        elif smap_data['close'][i] < smap_data['smap_wks10'][i]:\n",
        "            if signal != -1:\n",
        "                signal = -1\n",
        "                signal7.append(signal)\n",
        "            else:\n",
        "                signal7.append(0)\n",
        "        else:\n",
        "            signal7.append(0)\n",
        "\n",
        "#The 1 week moving average is trading above the 2 weeks moving average indicating bullish short term trading signal\n",
        "    signal = 0\n",
        "    for i in range(len(smap_data)):\n",
        "        if smap_data['smap_wks1'][i] > smap_data['smap_wks2'][i]:\n",
        "            if signal != 1:\n",
        "                signal = 1\n",
        "                signal8.append(signal)\n",
        "            else:\n",
        "                signal8.append(0)\n",
        "        elif smap_data['smap_wks1'][i] < smap_data['smap_wks2'][i]:\n",
        "            if signal != -1:\n",
        "                signal = -1\n",
        "                signal8.append(signal)\n",
        "            else:\n",
        "                signal8.append(0)\n",
        "        else:\n",
        "            signal8.append(0)\n",
        "\n",
        "#Combine all eight signals to get the unified smap signal satisfying all conditions\n",
        "    signal = 0\n",
        "    for i in range(len(smap_data)):\n",
        "        if ((signal1[i]==1 and signal2[i]==1) and (signal3[i]==1 and signal4[i]==1)) and ((signal5[i]==1 and signal6[i]==1) and (signal7[i]==1 and signal8[i]==1)):\n",
        "            if signal != 1:\n",
        "                buy_price.append(smap_data['close'][i])\n",
        "                sell_price.append(np.nan)\n",
        "                signal = 1\n",
        "                smap_signal.append(signal)\n",
        "            else:\n",
        "                buy_price.append(np.nan)\n",
        "                sell_price.append(np.nan)\n",
        "                smap_signal.append(0)\n",
        "        elif ((signal1[i]==-1 and signal2[i]==-1) and (signal3[i]==-1 and signal4[i]==-1)) and ((signal5[i]==-1 and signal6[i]==-1) and (signal7[i]==-1 and signal8[i]==-1)):\n",
        "            if signal != -1:\n",
        "                buy_price.append(np.nan)\n",
        "                sell_price.append(smap_data['close'][i])\n",
        "                signal = -1\n",
        "                smap_signal.append(signal)\n",
        "            else:\n",
        "                buy_price.append(np.nan)\n",
        "                sell_price.append(np.nan)\n",
        "                smap_signal.append(0)\n",
        "        else:\n",
        "            buy_price.append(np.nan)\n",
        "            sell_price.append(np.nan)\n",
        "            smap_signal.append(0)\n",
        "\n",
        "#Evaluate stock position based on the combined signals\n",
        "    for i in range(len(smap_data)):\n",
        "      if smap_signal[i] == 1:\n",
        "        position[i] = 1\n",
        "      elif smap_signal[i] == -1:\n",
        "        position[i] = 0\n",
        "      elif (smap_signal[i] == 0) and (i == 0):\n",
        "        position[i] = 0\n",
        "      else:\n",
        "        position[i] = position[i-1]\n",
        "\n",
        "    smap_signal = pd.DataFrame(smap_signal).rename(columns = {0:'smap_signal'}).set_index(smap_data.index)\n",
        "    position = pd.DataFrame(position).rename(columns = {0:'smap_position'}).set_index(smap_data.index)\n",
        "    buy_price = pd.DataFrame(buy_price).rename(columns = {0:'buy_price'}).set_index(smap_data.index)\n",
        "    sell_price = pd.DataFrame(sell_price).rename(columns = {0:'sell_price'}).set_index(smap_data.index)\n",
        "\n",
        "    signal1 = pd.DataFrame(signal1).rename(columns = {0:'signal1'}).set_index(smap_data.index)\n",
        "    signal2 = pd.DataFrame(signal2).rename(columns = {0:'signal2'}).set_index(smap_data.index)\n",
        "    signal3 = pd.DataFrame(signal3).rename(columns = {0:'signal3'}).set_index(smap_data.index)\n",
        "    signal4 = pd.DataFrame(signal4).rename(columns = {0:'signal4'}).set_index(smap_data.index)\n",
        "    signal5 = pd.DataFrame(signal5).rename(columns = {0:'signal5'}).set_index(smap_data.index)\n",
        "    signal6 = pd.DataFrame(signal6).rename(columns = {0:'signal6'}).set_index(smap_data.index)\n",
        "    signal7 = pd.DataFrame(signal7).rename(columns = {0:'signal7'}).set_index(smap_data.index)\n",
        "    signal8 = pd.DataFrame(signal8).rename(columns = {0:'signal8'}).set_index(smap_data.index)\n",
        "\n",
        "    smap_decisions = pd.concat([smap_data['close'], smap_signal, position, buy_price, sell_price, signal1, signal2, signal3, signal4, signal5, signal6, signal7, signal8], join = 'inner', axis = 1)\n",
        "\n",
        "\n",
        "    return smap_decisions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM1OxARmMrU9"
      },
      "source": [
        "def strategy_smav(smav_data):    \n",
        "    buy_price = []\n",
        "    sell_price = []\n",
        "    smav_signal = []\n",
        "    position = np.zeros(len(smav_data))\n",
        "\n",
        "    tradv_signal = []\n",
        "    \n",
        "#If volume is above the 50-day moving average, that is a bullish signal. \n",
        "    signal = 0\n",
        "    for i in range(len(smav_data)):\n",
        "        if smav_data['volume'][i] > smav_data['smav_wks10'][i]:\n",
        "            if signal != 1:\n",
        "                buy_price.append(smav_data['close'][i])\n",
        "                sell_price.append(np.nan)\n",
        "                signal = 1\n",
        "                smav_signal.append(signal)\n",
        "            else:\n",
        "                buy_price.append(np.nan)\n",
        "                sell_price.append(np.nan)\n",
        "                smav_signal.append(0)\n",
        "        elif smav_data['volume'][i] < smav_data['smav_wks10'][i]:\n",
        "            if signal != -1:\n",
        "                buy_price.append(np.nan)\n",
        "                sell_price.append(smav_data['close'][i])\n",
        "                signal = -1\n",
        "                smav_signal.append(signal)\n",
        "            else:\n",
        "                buy_price.append(np.nan)\n",
        "                sell_price.append(np.nan)\n",
        "                smav_signal.append(0)\n",
        "        else:\n",
        "            buy_price.append(np.nan)\n",
        "            sell_price.append(np.nan)\n",
        "            smav_signal.append(0)\n",
        "\n",
        "#For day-trading purposes, if volume is above the 10-day moving average, that is a bullish signal - NOTE: I added this signal for trading purposes on high volatility stocks\n",
        "    signal = 0\n",
        "    for i in range(len(smav_data)):\n",
        "        if smav_data['volume'][i] > smav_data['smav_wks2'][i]:\n",
        "            if signal != 1:\n",
        "                signal = 1\n",
        "                tradv_signal.append(signal)\n",
        "            else:\n",
        "                tradv_signal.append(0)\n",
        "        elif smav_data['volume'][i] < smav_data['smav_wks2'][i]:\n",
        "            if signal != -1:\n",
        "                signal = -1\n",
        "                tradv_signal.append(signal)\n",
        "            else:\n",
        "                tradv_signal.append(0)\n",
        "        else:\n",
        "            tradv_signal.append(0)\n",
        "\n",
        "#Evaluate stock position based on the smav signals\n",
        "    for i in range(len(smav_data)):\n",
        "      if smav_signal[i] == 1:\n",
        "        position[i] = 1\n",
        "      elif smav_signal[i] == -1:\n",
        "        position[i] = 0\n",
        "      elif (smav_signal[i] == 0) and (i == 0):\n",
        "        position[i] = 0\n",
        "      else:\n",
        "        position[i] = position[i-1]\n",
        "\n",
        "    smav_signal = pd.DataFrame(smav_signal).rename(columns = {0:'smav_signal'}).set_index(smav_data.index)\n",
        "    position = pd.DataFrame(position).rename(columns = {0:'smav_position'}).set_index(smav_data.index)\n",
        "    buy_price = pd.DataFrame(buy_price).rename(columns = {0:'buy_price'}).set_index(smav_data.index)\n",
        "    sell_price = pd.DataFrame(sell_price).rename(columns = {0:'sell_price'}).set_index(smav_data.index)\n",
        "\n",
        "    tradv_signal = pd.DataFrame(tradv_signal).rename(columns = {0:'tradv_signal'}).set_index(smav_data.index)\n",
        "\n",
        "    smav_decisions = pd.concat([smav_data['close'], smav_signal, position, buy_price, sell_price, tradv_signal], join = 'inner', axis = 1)\n",
        "\n",
        "\n",
        "    return smav_decisions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-QFTnDUgxqm"
      },
      "source": [
        "def strategy_stochst(stochst_data, oversold=20, overbought=80):    \n",
        "    buy_price = []\n",
        "    sell_price = []\n",
        "    stochst_signal = []\n",
        "    position = np.zeros(len(stochst_data))\n",
        "    signal = 0\n",
        "\n",
        "    for i in range(len(stochst_data)):\n",
        "        if stochst_data['d_slow'][i] < oversold:\n",
        "            if signal != 1:\n",
        "                buy_price.append(stochst_data['close'][i])\n",
        "                sell_price.append(np.nan)\n",
        "                signal = 1\n",
        "                stochst_signal.append(signal)\n",
        "            else:\n",
        "                buy_price.append(np.nan)\n",
        "                sell_price.append(np.nan)\n",
        "                stochst_signal.append(0)\n",
        "        elif stochst_data['d_slow'][i] > overbought:\n",
        "            if signal != -1:\n",
        "                buy_price.append(np.nan)\n",
        "                sell_price.append(stochst_data['close'][i])\n",
        "                signal = -1\n",
        "                stochst_signal.append(signal)\n",
        "            else:\n",
        "                buy_price.append(np.nan)\n",
        "                sell_price.append(np.nan)\n",
        "                stochst_signal.append(0)\n",
        "        else:\n",
        "            buy_price.append(np.nan)\n",
        "            sell_price.append(np.nan)\n",
        "            stochst_signal.append(0)\n",
        "\n",
        "    for i in range(len(stochst_data['close'])):\n",
        "      if stochst_signal[i] == 1:\n",
        "        position[i] = 1\n",
        "      elif stochst_signal[i] == -1:\n",
        "        position[i] = 0\n",
        "      elif (stochst_signal[i] == 0) and (i == 0):\n",
        "        position[i] = 0\n",
        "      else:\n",
        "        position[i] = position[i-1]\n",
        "\n",
        "    stochst_signal = pd.DataFrame(stochst_signal).rename(columns = {0:'stochst_signal'}).set_index(stochst_data.index)\n",
        "    position = pd.DataFrame(position).rename(columns = {0:'stochst_position'}).set_index(stochst_data.index)\n",
        "    buy_price = pd.DataFrame(buy_price).rename(columns = {0:'buy_price'}).set_index(stochst_data.index)\n",
        "    sell_price = pd.DataFrame(sell_price).rename(columns = {0:'sell_price'}).set_index(stochst_data.index)\n",
        "\n",
        "    stochst_decisions = pd.concat([stochst_data['close'], stochst_data['d_fast'], stochst_data['d_slow'], stochst_signal, position, buy_price, sell_price], join = 'inner', axis = 1)\n",
        "\n",
        "\n",
        "    return stochst_decisions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8YuldC0bZ_f"
      },
      "source": [
        "def strategy_boband(boband_data):    \n",
        "    buy_price = []\n",
        "    sell_price = []\n",
        "    boband_signal = []\n",
        "    position = np.zeros(len(boband_data))\n",
        "    signal = 0\n",
        "\n",
        "    for i in range(len(boband_data)):\n",
        "        if boband_data['close'][i] == boband_data['Lband'][i]:\n",
        "            if signal != 1:\n",
        "                buy_price.append(boband_data['close'][i])\n",
        "                sell_price.append(np.nan)\n",
        "                signal = 1\n",
        "                boband_signal.append(signal)\n",
        "            else:\n",
        "                buy_price.append(np.nan)\n",
        "                sell_price.append(np.nan)\n",
        "                boband_signal.append(0)\n",
        "        elif boband_data['close'][i] == boband_data['Uband'][i]:\n",
        "            if signal != -1:\n",
        "                buy_price.append(np.nan)\n",
        "                sell_price.append(boband_data['close'][i])\n",
        "                signal = -1\n",
        "                boband_signal.append(signal)\n",
        "            else:\n",
        "                buy_price.append(np.nan)\n",
        "                sell_price.append(np.nan)\n",
        "                boband_signal.append(0)\n",
        "        else:\n",
        "            buy_price.append(np.nan)\n",
        "            sell_price.append(np.nan)\n",
        "            boband_signal.append(0)\n",
        "\n",
        "    for i in range(len(boband_data)):\n",
        "      if boband_signal[i] == 1:\n",
        "        position[i] = 1\n",
        "      elif boband_signal[i] == -1:\n",
        "        position[i] = 0\n",
        "      elif (boband_signal[i] == 0) and (i == 0):\n",
        "        position[i] = 0\n",
        "      else:\n",
        "        position[i] = position[i-1]\n",
        "\n",
        "    boband_signal = pd.DataFrame(boband_signal).rename(columns = {0:'boband_signal'}).set_index(boband_data.index)\n",
        "    position = pd.DataFrame(position).rename(columns = {0:'boband_position'}).set_index(boband_data.index)\n",
        "    buy_price = pd.DataFrame(buy_price).rename(columns = {0:'buy_price'}).set_index(boband_data.index)\n",
        "    sell_price = pd.DataFrame(sell_price).rename(columns = {0:'sell_price'}).set_index(boband_data.index)\n",
        "\n",
        "    boband_decisions = pd.concat([boband_data['close'], boband_data['Lband'], boband_data['Uband'], boband_signal, position, buy_price, sell_price], join = 'inner', axis = 1)\n",
        "\n",
        "\n",
        "    return boband_decisions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0YF0wNhaiV4"
      },
      "source": [
        "def scenarios_invest(macd_decisions, smap_decisions, smav_decisions, stochst_decisions, boband_decisions):\n",
        "  \"\"\"\n",
        "  Investment Scenarios\n",
        "  -High Risk (HR): based on only smap and smav \n",
        "  -Medium Risk (MR): based on smap, smav, macd, and stochastic\n",
        "  -Low Risk (LR): based on smap, smav, macd, stochastic, and bollinger\n",
        "  \"\"\"\n",
        "\n",
        "  df = pd.concat([macd_decisions, smap_decisions, smav_decisions, stochst_decisions, boband_decisions], join = 'inner', axis = 1)\n",
        "\n",
        "  HR_signal = []\n",
        "  MR_signal = []\n",
        "  LR_signal = []\n",
        "  HR_position = np.zeros(len(df))\n",
        "  MR_position = np.zeros(len(df))\n",
        "  LR_position = np.zeros(len(df))\n",
        "\n",
        "\n",
        "#HR SIGNAL CONDITIONS\n",
        "  signal = 0\n",
        "  for i in range(len(df)):\n",
        "      if (df['smap_signal'][i] == 1) and (df['smav_signal'][i] == 1):\n",
        "          if signal != 1:\n",
        "              signal = 1\n",
        "              HR_signal.append(signal)\n",
        "          else:\n",
        "              HR_signal.append(0)\n",
        "      elif (df['smap_signal'][i] == -1) and (df['smav_signal'][i] == -1):\n",
        "          if signal != -1:\n",
        "              signal = -1\n",
        "              HR_signal.append(signal)\n",
        "          else:\n",
        "              HR_signal.append(0)\n",
        "      else:\n",
        "          HR_signal.append(0)\n",
        "\n",
        "#MR SIGNAL CONDITIONS\n",
        "  signal = 0\n",
        "  for i in range(len(df)):\n",
        "      if ((df['smap_signal'][i] == 1) and (df['smav_signal'][i] == 1)) and ((df['macd_signal'][i] == 1) and (df['stochst_signal'][i] == 1)):\n",
        "          if signal != 1:\n",
        "              signal = 1\n",
        "              MR_signal.append(signal)\n",
        "          else:\n",
        "              MR_signal.append(0)\n",
        "      elif ((df['smap_signal'][i] == -1) and (df['smav_signal'][i] == -1)) and ((df['macd_signal'][i] == -1) and (df['stochst_signal'][i] == -1)):\n",
        "          if signal != -1:\n",
        "              signal = -1\n",
        "              MR_signal.append(signal)\n",
        "          else:\n",
        "              MR_signal.append(0)\n",
        "      else:\n",
        "          MR_signal.append(0)\n",
        "\n",
        "#LR SIGNAL CONDITIONS\n",
        "  signal = 0\n",
        "  for i in range(len(df)):\n",
        "      if (((df['smap_signal'][i] == 1) and (df['smav_signal'][i] == 1)) and ((df['macd_signal'][i] == 1) and (df['stochst_signal'][i] == 1))) and (df['boband_signal'][i] == 1):\n",
        "          if signal != 1:\n",
        "              signal = 1\n",
        "              LR_signal.append(signal)\n",
        "          else:\n",
        "              LR_signal.append(0)\n",
        "      elif (((df['smap_signal'][i] == -1) and (df['smav_signal'][i] == -1)) and ((df['macd_signal'][i] == -1) and (df['stochst_signal'][i] == -1))) and (df['boband_signal'][i] == -1):\n",
        "          if signal != -1:\n",
        "              signal = -1\n",
        "              LR_signal.append(signal)\n",
        "          else:\n",
        "              LR_signal.append(0)\n",
        "      else:\n",
        "          LR_signal.append(0)\n",
        "\n",
        "\n",
        "#HR POSITION CONDITIONS\n",
        "  for i in range(len(df)):\n",
        "    if HR_signal[i] == 1:\n",
        "      HR_position[i] = 1\n",
        "    elif HR_signal[i] == -1:\n",
        "      HR_position[i] = 0\n",
        "    elif (HR_signal[i] == 0) and (i == 0):\n",
        "      HR_position[i] = 0\n",
        "    else:\n",
        "      HR_position[i] = HR_position[i-1]\n",
        "\n",
        "#MR POSITION CONDITIONS\n",
        "  for i in range(len(df)):\n",
        "    if MR_signal[i] == 1:\n",
        "      MR_position[i] = 1\n",
        "    elif MR_signal[i] == -1:\n",
        "      MR_position[i] = 0\n",
        "    elif (MR_signal[i] == 0) and (i == 0):\n",
        "      MR_position[i] = 0\n",
        "    else:\n",
        "      MR_position[i] = MR_position[i-1]\n",
        "\n",
        "#LR POSITION CONDITIONS\n",
        "  for i in range(len(df)):\n",
        "    if LR_signal[i] == 1:\n",
        "      LR_position[i] = 1\n",
        "    elif LR_signal[i] == -1:\n",
        "      LR_position[i] = 0\n",
        "    elif (LR_signal[i] == 0) and (i == 0):\n",
        "      LR_position[i] = 0\n",
        "    else:\n",
        "      LR_position[i] = LR_position[i-1]\n",
        "\n",
        "\n",
        "  HR_signal = pd.DataFrame(HR_signal).rename(columns = {0:'HR_signal'}).set_index(df.index)\n",
        "  MR_signal = pd.DataFrame(MR_signal).rename(columns = {0:'MR_signal'}).set_index(df.index)\n",
        "  LR_signal = pd.DataFrame(LR_signal).rename(columns = {0:'LR_signal'}).set_index(df.index)\n",
        "\n",
        "  HR_position = pd.DataFrame(HR_position).rename(columns = {0:'HR_position'}).set_index(df.index)\n",
        "  MR_position = pd.DataFrame(MR_position).rename(columns = {0:'MR_position'}).set_index(df.index)\n",
        "  LR_position = pd.DataFrame(LR_position).rename(columns = {0:'LR_position'}).set_index(df.index)\n",
        "\n",
        "# invest_table = pd.concat([df['close'], HR_signal, MR_signal, LR_signal, HR_position, MR_position, LR_position], join = 'inner', axis = 1)\n",
        "  invest_table = pd.concat([macd_decisions['close'], HR_signal, MR_signal, LR_signal, HR_position, MR_position, LR_position], join = 'inner', axis = 1)\n",
        "\n",
        "  return invest_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQxzbyR5A_Rj"
      },
      "source": [
        "def scenarios_tradin(macd_decisions, smap_decisions, smav_decisions, stochst_decisions, boband_decisions):\n",
        "\n",
        "  \"\"\"\n",
        "  Trading Scenarios (all considered high risk)\n",
        "  -Short View (SV): uses one and two weeks trends (5 and 10 days) ...smap, smav, boband\n",
        "  -Medium View (MV): uses one and two weeks trends (5 and 10 days)...smap, smav, macd, stochst\n",
        "  -Long View (LV): uses current price and ten weeks trends (close and 50 days)...smap, smav, macd, boband\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  df = pd.concat([macd_decisions, smap_decisions, smav_decisions, stochst_decisions, boband_decisions], join = 'inner', axis = 1)\n",
        "\n",
        "  SV_signal = []\n",
        "  MV_signal = []\n",
        "  LV_signal = []\n",
        "  SV_position = np.zeros(len(df))\n",
        "  MV_position = np.zeros(len(df))\n",
        "  LV_position = np.zeros(len(df))\n",
        "\n",
        "  #SV SIGNAL CONDITIONS\n",
        "  signal = 0\n",
        "  for i in range(len(df)):\n",
        "      if ((df['signal8'][i] == 1) and (df['tradv_signal'][i] == 1)) and (df['boband_signal'][i] == 1):\n",
        "          if signal != 1:\n",
        "              signal = 1\n",
        "              SV_signal.append(signal)\n",
        "          else:\n",
        "              SV_signal.append(0)\n",
        "      elif ((df['signal8'][i] == -1) and (df['tradv_signal'][i] == -1)) and (df['boband_signal'][i] == -1):\n",
        "          if signal != -1:\n",
        "              signal = -1\n",
        "              SV_signal.append(signal)\n",
        "          else:\n",
        "              SV_signal.append(0)\n",
        "      else:\n",
        "          SV_signal.append(0)\n",
        "\n",
        "  #MV SIGNAL CONDITIONS\n",
        "  signal = 0\n",
        "  for i in range(len(df)):\n",
        "      if ((df['signal8'][i] == 1) and (df['tradv_signal'][i] == 1)) and ((df['macd_signal'][i] == 1) and (df['stochst_signal'][i] == 1)):\n",
        "          if signal != 1:\n",
        "              signal = 1\n",
        "              MV_signal.append(signal)\n",
        "          else:\n",
        "              MV_signal.append(0)\n",
        "      elif ((df['signal8'][i] == -1) and (df['tradv_signal'][i] == -1)) and ((df['macd_signal'][i] == -1) and (df['stochst_signal'][i] == -1)):\n",
        "          if signal != -1:\n",
        "              signal = -1\n",
        "              MV_signal.append(signal)\n",
        "          else:\n",
        "              MV_signal.append(0)\n",
        "      else:\n",
        "          MV_signal.append(0)\n",
        "\n",
        "  #LV SIGNAL CONDITIONS\n",
        "  signal = 0\n",
        "  for i in range(len(df)):\n",
        "      if ((df['signal7'][i] == 1) and (df['smav_signal'][i] == 1)) and ((df['macd_signal'][i] == 1) and (df['boband_signal'][i] == 1)):\n",
        "          if signal != 1:\n",
        "              signal = 1\n",
        "              LV_signal.append(signal)\n",
        "          else:\n",
        "              LV_signal.append(0)\n",
        "      elif ((df['signal7'][i] == -1) and (df['smav_signal'][i] == -1)) and ((df['macd_signal'][i] == -1) and (df['boband_signal'][i] == -1)):\n",
        "          if signal != -1:\n",
        "              signal = -1\n",
        "              LV_signal.append(signal)\n",
        "          else:\n",
        "              LV_signal.append(0)\n",
        "      else:\n",
        "          LV_signal.append(0)\n",
        "\n",
        "\n",
        "#SV POSITION CONDITIONS\n",
        "  for i in range(len(df)):\n",
        "    if SV_signal[i] == 1:\n",
        "      SV_position[i] = 1\n",
        "    elif SV_signal[i] == -1:\n",
        "      SV_position[i] = 0\n",
        "    elif (SV_signal[i] == 0) and (i == 0):\n",
        "      SV_position[i] = 0\n",
        "    else:\n",
        "      SV_position[i] = SV_position[i-1]\n",
        "\n",
        "#MV POSITION CONDITIONS\n",
        "  for i in range(len(df)):\n",
        "    if MV_signal[i] == 1:\n",
        "      MV_position[i] = 1\n",
        "    elif MV_signal[i] == -1:\n",
        "      MV_position[i] = 0\n",
        "    elif (MV_signal[i] == 0) and (i == 0):\n",
        "      MV_position[i] = 0\n",
        "    else:\n",
        "      MV_position[i] = MV_position[i-1]\n",
        "\n",
        "#LV POSITION CONDITIONS\n",
        "  for i in range(len(df)):\n",
        "    if LV_signal[i] == 1:\n",
        "      LV_position[i] = 1\n",
        "    elif LV_signal[i] == -1:\n",
        "      LV_position[i] = 0\n",
        "    elif (LV_signal[i] == 0) and (i == 0):\n",
        "      LV_position[i] = 0\n",
        "    else:\n",
        "      LV_position[i] = LV_position[i-1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  SV_signal = pd.DataFrame(SV_signal).rename(columns = {0:'SV_signal'}).set_index(df.index)\n",
        "  MV_signal = pd.DataFrame(MV_signal).rename(columns = {0:'MV_signal'}).set_index(df.index)\n",
        "  LV_signal = pd.DataFrame(LV_signal).rename(columns = {0:'LV_signal'}).set_index(df.index)\n",
        "\n",
        "  SV_position = pd.DataFrame(SV_position).rename(columns = {0:'SV_position'}).set_index(df.index)\n",
        "  MV_position = pd.DataFrame(MV_position).rename(columns = {0:'MV_position'}).set_index(df.index)\n",
        "  LV_position = pd.DataFrame(LV_position).rename(columns = {0:'LV_position'}).set_index(df.index)\n",
        "\n",
        "  #tradin_table = pd.concat([df['close'], SV_signal, MV_signal, LV_signal, SV_position, MV_position, LV_position], join = 'inner', axis = 1)  \n",
        "  tradin_table = pd.concat([macd_decisions['close'], SV_signal, MV_signal, LV_signal, SV_position, MV_position, LV_position], join = 'inner', axis = 1)\n",
        "\n",
        "  return tradin_table\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bCdxmaPwaet5"
      },
      "source": [
        "\"\"\"\n",
        "WORKFLOW EXECUTION SCRIPT: THIS IS USED TO RUN THE TRADING MODULES ON OFFLINE BASIS\n",
        "\n",
        "\"\"\"\n",
        "#Selection of stocks for trading or investment\n",
        "grouped_stocks='tsx'\n",
        "ticker_list = get_ticker_list(grouped_stocks)                                             #Other currently available groups are: 'tsx', 'sp500', 'nasdaq' \n",
        "\n",
        "#Get (historical) data on longterm performance os stock - 20 years preferable\n",
        "start_date = (datetime.date.today() + datetime.timedelta(days=-3)).strftime(\"%m/%d/%Y\")                                                            #Input format is: month/day/Year\n",
        "end_date = datetime.date.today().strftime(\"%m/%d/%Y\")\n",
        "trading_datas = get_trading_data(ticker_list, start_date, end_date, index_as_date = True, interval = \"1d\")\n",
        "\n",
        "#Select stocks based on attributes/performance for investment or trading\n",
        "tradin_select, _, volatl_select = get_selection(trading_datas)\n",
        "if len(tradin_select) == 0:\n",
        "  tradin_select = volatl_select\n",
        "\n",
        "\n",
        "output_text = str(grouped_stocks) +  \"_watchlist.txt\"\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/{}'.format(str(output_text)), \"w\") as text_file:\n",
        "  print(tradin_select, file=text_file)\n",
        "\n",
        "\n",
        "ticker_list = volatl_select \n",
        "start_date = (datetime.date.today() + datetime.timedelta(days=-7300)).strftime(\"%m/%d/%Y\")                                                            #Input format is: month/day/Year\n",
        "end_date = datetime.date.today().strftime(\"%m/%d/%Y\")\n",
        "trading_datas = get_trading_data(ticker_list, start_date, end_date, index_as_date = True, interval = \"1d\")\n",
        "\n",
        "\n",
        "\n",
        "#############################################TRADING#####################################################################################################################\n",
        "#Call algotrading methods for selected stocks for Day-Trading\n",
        "fastm, slowm, smooth = 6, 17, 10                    #MACD parameters\n",
        "roll_period = 4                                     #Bollinger Bands parameter\n",
        "roll_low, roll_high, fasts, slows = 5, 14, 7, 14    #Stochastic bands parameters\n",
        "roll_wks1, roll_wks2, roll_wks10, roll_wks30, roll_wks40 = 5, 10, 50, 150, 200      #Simple moving average parameters\n",
        "\n",
        "macd_datat, boband_datat, stochst_datat, smap_datat, smav_datat = {}, {}, {}, {}, {}\n",
        "\n",
        "for select_ticker in tradin_select:\n",
        "  macd_datat[select_ticker] = get_macd(trading_datas, select_ticker, fastm, slowm, smooth)\n",
        "  boband_datat[select_ticker] = get_boband(trading_datas, select_ticker, roll_period)\n",
        "  stochst_datat[select_ticker] = get_stochst(trading_datas, select_ticker, roll_low, roll_high, fasts, slows)\n",
        "  smap_datat[select_ticker] = get_smap(trading_datas, select_ticker, roll_wks1, roll_wks2, roll_wks10, roll_wks30, roll_wks40)\n",
        "  smav_datat[select_ticker] = get_smav(trading_datas, select_ticker, roll_wks1, roll_wks2, roll_wks10, roll_wks30, roll_wks40)  \n",
        "\n",
        "macd_datat = pd.concat(macd_datat).reset_index().drop(labels = 'level_0', axis = 1).set_index('date')\n",
        "boband_datat = pd.concat(boband_datat).reset_index().drop(labels = 'level_0', axis = 1).set_index('date')\n",
        "stochst_datat = pd.concat(stochst_datat).reset_index().drop(labels = 'level_0', axis = 1).set_index('date')\n",
        "smap_datat = pd.concat(smap_datat).reset_index().drop(labels = 'level_0', axis = 1).set_index('date')\n",
        "smav_datat = pd.concat(smav_datat).reset_index().drop(labels = 'level_0', axis = 1).set_index('date')\n",
        "\n",
        "#Evaluate the strategy of each trading decision method\n",
        "macd_decisiont, smap_decisiont, smav_decisiont, stochst_decisiont, boband_decisiont = {}, {}, {}, {}, {}\n",
        "for select_ticker in tradin_select:\n",
        "  macd_decisiont[select_ticker] = strategy_macd(macd_data = macd_datat[macd_datat['ticker'] == select_ticker])\n",
        "  smap_decisiont[select_ticker] = strategy_smap(smap_data = smap_datat[smap_datat['ticker'] == select_ticker])\n",
        "  smav_decisiont[select_ticker] = strategy_smav(smav_data = smav_datat[smav_datat['ticker'] == select_ticker])\n",
        "  stochst_decisiont[select_ticker] = strategy_stochst(stochst_data = stochst_datat[stochst_datat['ticker'] == select_ticker])\n",
        "  boband_decisiont[select_ticker] = strategy_boband(boband_data = boband_datat[boband_datat['ticker'] == select_ticker])\n",
        "\n",
        "macd_decisiont = pd.concat(macd_decisiont).reset_index().rename(columns = {'level_0':'ticker'}).set_index('date')\n",
        "boband_decisiont = pd.concat(boband_decisiont).reset_index().rename(columns = {'level_0':'ticker'}).set_index('date')\n",
        "stochst_decisiont = pd.concat(stochst_decisiont).reset_index().rename(columns = {'level_0':'ticker'}).set_index('date')\n",
        "smap_decisiont = pd.concat(smap_decisiont).reset_index().rename(columns = {'level_0':'ticker'}).set_index('date')\n",
        "smav_decisiont = pd.concat(smav_decisiont).reset_index().rename(columns = {'level_0':'ticker'}).set_index('date')\n",
        "\n",
        "#Evaluate trading scenarios\n",
        "tradin_table = {}\n",
        "for select_ticker in tradin_select:\n",
        "  tradin_table[select_ticker] = scenarios_tradin(macd_decisiont[macd_decisiont['ticker'] == select_ticker], smap_decisiont[smap_decisiont['ticker'] == select_ticker],\\\n",
        "                                                 smav_decisiont[smav_decisiont['ticker'] == select_ticker], stochst_decisiont[stochst_decisiont['ticker'] == select_ticker],\\\n",
        "                                                 boband_decisiont[boband_decisiont['ticker'] == select_ticker])\n",
        "\n",
        "tradin_table = pd.concat(tradin_table).reset_index().rename(columns = {'level_0':'ticker'}).set_index('date')\n",
        "\n",
        "########################################################################################################################################################################\n",
        "\n",
        "\n",
        "\n",
        "########################################################BACK TESTING####################################################################################################\n",
        "#Trading\n",
        "SV_return = sum(tradin_table['close']*tradin_table['SV_signal'])*(-1)            #multiply by -1 so that profit is +ve and loss is -ve\n",
        "MV_return = sum(tradin_table['close']*tradin_table['MV_signal'])*(-1)\n",
        "LV_return = sum(tradin_table['close']*tradin_table['LV_signal'])*(-1)\n",
        "\n",
        "backtest_tradin = {'short view': SV_return, 'medium view': MV_return, 'long view': LV_return}\n",
        "\n",
        "output_text = str(grouped_stocks) +  \"_backtest.txt\"\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/{}'.format(str(output_text)), \"w\") as text_file:\n",
        "  print(backtest_tradin, file=text_file)\n",
        "\n",
        "np.count_nonzero(tradin_table['SV_signal']>0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dsi7P-9dPRC4",
        "outputId": "a7f0a4f4-9cab-44c1-fb4c-bd2bb4bfda4b"
      },
      "source": [
        "\"\"\"\n",
        "WORKFLOW EXECUTION SCRIPT: THIS IS USED TO RUN THE TRADING MODULES ON REAL-TIME BASIS\n",
        "\n",
        "\"\"\"\n",
        "#Selection of stocks for trading or investment\n",
        "ticker_list = get_ticker_list(grouped_stocks='tsx')                                             #Other currently available groups are: 'tsx', 'sp500', 'nasdaq' \n",
        "\n",
        "#Get (historical) data on longterm performance os stock - 20 years preferable\n",
        "start_date = (datetime.date.today() + datetime.timedelta(days=-366)).strftime(\"%m/%d/%Y\")                                                            #Input format is: month/day/Year\n",
        "end_date = (datetime.date.today() + datetime.timedelta(days=-1)).strftime(\"%m/%d/%Y\")\n",
        "trading_datas = get_trading_data(ticker_list, start_date, end_date, index_as_date = True, interval = \"1d\")\n",
        "\n",
        "#Select stocks based on attributes/performance for investment or trading\n",
        "tradin_select, _, volatl_select = get_selection(trading_datas)\n",
        "if len(tradin_select) == 0:\n",
        "  tradin_select = volatl_select\n",
        "\n",
        "\n",
        "#Get (real-time) data for trading decisions\n",
        "tradin_data = {}\n",
        "\n",
        "for ticker in tradin_select:                                                                     #volatl_select could be used if tradin_select is empty\n",
        "  tradin_data[ticker] = yf.download(ticker, period = \"1d\", interval = \"5m\", auto_adjust=True)\n",
        "\n",
        "tradin_data = pd.concat(tradin_data)\n",
        "\n",
        "tradin_data = tradin_data.reset_index()\\\n",
        "                         .rename(columns={'level_0':'ticker'})\\\n",
        "                         .rename(columns={'Datetime':'date'})\\\n",
        "                         .set_index('date')\\\n",
        "                         .rename(columns={'Close':'close'})\\\n",
        "                         .rename(columns={'Open':'open'})\\\n",
        "                         .rename(columns={'High':'high'})\\\n",
        "                         .rename(columns={'Low':'low'})\\\n",
        "                         .rename(columns={'Volume':'volume'})\\\n",
        "                         .dropna()\n",
        "\n",
        "#Combine the realtime (tradin_data) and historical (trading_datas) trading data get day-trading data\n",
        "daytrading_data = {}\n",
        "for ticker in tradin_select:\n",
        "  daytrading_data[ticker] = trading_datas[trading_datas['ticker'] == ticker].drop(labels=['adjclose', 'prange'], axis =1)\n",
        "\n",
        "daytrading_data = pd.concat(daytrading_data)\n",
        "daytrading_data = daytrading_data.reset_index()\\\n",
        "                                 .drop(labels = 'level_0', axis = 1)\\\n",
        "                                 .set_index('date')\n",
        "\n",
        "daytrading_data = daytrading_data.append(tradin_data)\n",
        "\n",
        "\n",
        "#############################################TRADING########################################################################\n",
        "#Call algotrading methods for selected stocks for Day-Trading\n",
        "fastm, slowm, smooth = 6, 17, 10                    #MACD parameters\n",
        "roll_period = 4                                     #Bollinger Bands parameter\n",
        "roll_low, roll_high, fasts, slows = 5, 14, 7, 14    #Stochastic bands parameters\n",
        "roll_wks1, roll_wks2, roll_wks10, roll_wks30, roll_wks40 = 5, 10, 50, 150, 200      #Simple moving average parameters\n",
        "trading_datas = daytrading_data\n",
        "\n",
        "macd_datat, boband_datat, stochst_datat, smap_datat, smav_datat = {}, {}, {}, {}, {}\n",
        "\n",
        "for select_ticker in tradin_select:\n",
        "  macd_datat[select_ticker] = get_macd(trading_datas, select_ticker, fastm, slowm, smooth)\n",
        "  boband_datat[select_ticker] = get_boband(trading_datas, select_ticker, roll_period)\n",
        "  stochst_datat[select_ticker] = get_stochst(trading_datas, select_ticker, roll_low, roll_high, fasts, slows)\n",
        "  smap_datat[select_ticker] = get_smap(trading_datas, select_ticker, roll_wks1, roll_wks2, roll_wks10, roll_wks30, roll_wks40)\n",
        "  smav_datat[select_ticker] = get_smav(trading_datas, select_ticker, roll_wks1, roll_wks2, roll_wks10, roll_wks30, roll_wks40)  \n",
        "\n",
        "macd_datat = pd.concat(macd_datat).reset_index().drop(labels = 'level_0', axis = 1).set_index('date')\n",
        "boband_datat = pd.concat(boband_datat).reset_index().drop(labels = 'level_0', axis = 1).set_index('date')\n",
        "stochst_datat = pd.concat(stochst_datat).reset_index().drop(labels = 'level_0', axis = 1).set_index('date')\n",
        "smap_datat = pd.concat(smap_datat).reset_index().drop(labels = 'level_0', axis = 1).set_index('date')\n",
        "smav_datat = pd.concat(smav_datat).reset_index().drop(labels = 'level_0', axis = 1).set_index('date')\n",
        "\n",
        "#Evaluate the strategy of each trading decision method\n",
        "macd_decisiont, smap_decisiont, smav_decisiont, stochst_decisiont, boband_decisiont = {}, {}, {}, {}, {}\n",
        "for select_ticker in tradin_select:\n",
        "  macd_decisiont[select_ticker] = strategy_macd(macd_data = macd_datat[macd_datat['ticker'] == select_ticker])\n",
        "  smap_decisiont[select_ticker] = strategy_smap(smap_data = smap_datat[smap_datat['ticker'] == select_ticker])\n",
        "  smav_decisiont[select_ticker] = strategy_smav(smav_data = smav_datat[smav_datat['ticker'] == select_ticker])\n",
        "  stochst_decisiont[select_ticker] = strategy_stochst(stochst_data = stochst_datat[stochst_datat['ticker'] == select_ticker])\n",
        "  boband_decisiont[select_ticker] = strategy_boband(boband_data = boband_datat[boband_datat['ticker'] == select_ticker])\n",
        "\n",
        "macd_decisiont = pd.concat(macd_decisiont).reset_index().rename(columns = {'level_0':'ticker'}).set_index('date')\n",
        "boband_decisiont = pd.concat(boband_decisiont).reset_index().rename(columns = {'level_0':'ticker'}).set_index('date')\n",
        "stochst_decisiont = pd.concat(stochst_decisiont).reset_index().rename(columns = {'level_0':'ticker'}).set_index('date')\n",
        "smap_decisiont = pd.concat(smap_decisiont).reset_index().rename(columns = {'level_0':'ticker'}).set_index('date')\n",
        "smav_decisiont = pd.concat(smav_decisiont).reset_index().rename(columns = {'level_0':'ticker'}).set_index('date')\n",
        "\n",
        "#Evaluate trading scenarios\n",
        "tradin_table = {}\n",
        "for select_ticker in tradin_select:\n",
        "  tradin_table[select_ticker] = scenarios_tradin(macd_decisiont[macd_decisiont['ticker'] == select_ticker], smap_decisiont[smap_decisiont['ticker'] == select_ticker],\\\n",
        "                                                 smav_decisiont[smav_decisiont['ticker'] == select_ticker], stochst_decisiont[stochst_decisiont['ticker'] == select_ticker],\\\n",
        "                                                 boband_decisiont[boband_decisiont['ticker'] == select_ticker])\n",
        "\n",
        "tradin_table = pd.concat(tradin_table).reset_index().rename(columns = {'level_0':'ticker'}).set_index('date')\n",
        "\n",
        "###############################################################################################################################################\n",
        "\n",
        "\n",
        "\n",
        "########################################################BACK TESTING####################################################################################################\n",
        "#Trading\n",
        "SV_return = sum(tradin_table['close']*tradin_table['SV_signal'])*(-1)            #multiply by -1 so that profit is +ve and loss is -ve\n",
        "MV_return = sum(tradin_table['close']*tradin_table['MV_signal'])*(-1)\n",
        "LV_return = sum(tradin_table['close']*tradin_table['LV_signal'])*(-1)\n",
        "\n",
        "backtest_tradin = [SV_return, MV_return, LV_return]\n",
        "\n",
        "np.count_nonzero(tradin_table['SV_signal']>0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/yahoo_fin/stock_info.py:116: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "\n",
            "1 Failed download:\n",
            "- DXG: No data found for this date range, symbol may be delisted\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-df5e759b85d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mtradin_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtradin_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtradin_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtradin_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                         \u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'level_0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'ticker'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m                         \u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Datetime'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m                         \u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m)\u001b[0m                         \u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'close'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m                         \u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Open'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'open'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m                         \u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'High'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'high'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m                         \u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Low'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'low'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m                         \u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Volume'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'volume'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m                         \u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#Combine the realtime (tradin_data) and historical (trading_datas) trading data get day-trading data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   4553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4555\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of ['date'] are in the columns\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyNMFUxn8_sY"
      },
      "source": [
        "\"\"\"\n",
        "WORKFLOW EXECUTION SCRIPT: THIS IS USED TO RUN THE INVESTING MODULES ON REAL-TIME BASIS\n",
        "\n",
        "\"\"\"\n",
        "#Selection of stocks for trading or investment\n",
        "ticker_list = get_ticker_list(grouped_stocks='tsx60')                                             #Other currently available groups are: 'tsx', 'sp500', 'nasdaq' \n",
        "\n",
        "#Get (historical) data on longterm performance os stock - 20 years preferable\n",
        "start_date = (datetime.date.today() + datetime.timedelta(days=-366)).strftime(\"%m/%d/%Y\")                                                            #Input format is: month/day/Year\n",
        "end_date = (datetime.date.today() + datetime.timedelta(days=-1)).strftime(\"%m/%d/%Y\")\n",
        "trading_datas = get_trading_data(ticker_list, start_date, end_date, index_as_date = True, interval = \"1d\")\n",
        "\n",
        "#Select stocks based on attributes/performance for investment or trading\n",
        "_, invest_select, _ = get_selection(trading_datas)\n",
        "\n",
        "\n",
        "#Get (real-time) data for investment decisions\n",
        "invest_data = {}\n",
        "\n",
        "for ticker in invest_select:\n",
        "  invest_data[ticker] = yf.download(ticker, period = \"1d\", interval = \"5m\", auto_adjust=True)\n",
        "\n",
        "invest_data = pd.concat(invest_data)\n",
        "\n",
        "invest_data = invest_data.reset_index()\\\n",
        "                         .rename(columns={'level_0':'ticker'})\\\n",
        "                         .rename(columns={'Datetime':'date'})\\\n",
        "                         .set_index('date')\\\n",
        "                         .rename(columns={'Close':'close'})\\\n",
        "                         .rename(columns={'Open':'open'})\\\n",
        "                         .rename(columns={'High':'high'})\\\n",
        "                         .rename(columns={'Low':'low'})\\\n",
        "                         .rename(columns={'Volume':'volume'})\\\n",
        "                         .dropna()\n",
        "\n",
        "#Combine the realtime (invest_data) and historical (trading_datas) trading data get day-investing data\n",
        "dayinvesting_data = {}\n",
        "for ticker in invest_select:\n",
        "  dayinvesting_data[ticker] = trading_datas[trading_datas['ticker'] == ticker].drop(labels=['adjclose', 'prange'], axis =1)\n",
        "\n",
        "dayinvesting_data = pd.concat(dayinvesting_data)\n",
        "dayinvesting_data = dayinvesting_data.reset_index()\\\n",
        "                                     .drop(labels = 'level_0', axis = 1)\\\n",
        "                                     .set_index('date')\n",
        "\n",
        "dayinvesting_data = dayinvesting_data.append(invest_data)\n",
        "\n",
        "\n",
        "###############################################INVESTING#######################################################################################\n",
        "#Call algotrading methods for selected stocks for Day-Investing\n",
        "fastm, slowm, smooth = 6, 17, 10                                       #MACD parameters\n",
        "roll_period = 4                                                        #Bollinger Bands parameter\n",
        "roll_low, roll_high, fasts, slows = 5, 14, 7, 14                       #Stochastic bands parameters\n",
        "roll_wks1, roll_wks2, roll_wks10, roll_wks30, roll_wks40 = 5, 10, 50, 150, 200       #Simple moving average parameters\n",
        "trading_datas = dayinvesting_data\n",
        "\n",
        "macd_datai, boband_datai, stochst_datai, smap_datai, smav_datai = {}, {}, {}, {}, {}\n",
        "\n",
        "for select_ticker in invest_select:\n",
        "  macd_datai[select_ticker] = get_macd(trading_datas, select_ticker, fastm, slowm, smooth)\n",
        "  boband_datai[select_ticker] = get_boband(trading_datas, select_ticker, roll_period)\n",
        "  stochst_datai[select_ticker] = get_stochst(trading_datas, select_ticker, roll_low, roll_high, fasts, slows)\n",
        "  smap_datai[select_ticker] = get_smap(trading_datas, select_ticker, roll_wks1, roll_wks2, roll_wks10, roll_wks30, roll_wks40)\n",
        "  smav_datai[select_ticker] = get_smav(trading_datas, select_ticker, roll_wks1, roll_wks2, roll_wks10, roll_wks30, roll_wks40)  \n",
        "\n",
        "macd_datai = pd.concat(macd_datai).reset_index().drop(labels = 'level_0', axis = 1).set_index('date')\n",
        "boband_datai = pd.concat(boband_datai).reset_index().drop(labels = 'level_0', axis = 1).set_index('date')\n",
        "stochst_datai = pd.concat(stochst_datai).reset_index().drop(labels = 'level_0', axis = 1).set_index('date')\n",
        "smap_datai = pd.concat(smap_datai).reset_index().drop(labels = 'level_0', axis = 1).set_index('date')\n",
        "smav_datai = pd.concat(smav_datai).reset_index().drop(labels = 'level_0', axis = 1).set_index('date')\n",
        "\n",
        "\n",
        "#Evaluate the strategy of each investing decision method\n",
        "macd_decisioni, smap_decisioni, smav_decisioni, stochst_decisioni, boband_decisioni = {}, {}, {}, {}, {}\n",
        "for select_ticker in invest_select:\n",
        "  macd_decisioni[select_ticker] = strategy_macd(macd_data = macd_datai[macd_datai['ticker'] == select_ticker])\n",
        "  smap_decisioni[select_ticker] = strategy_smap(smap_data = smap_datai[smap_datai['ticker'] == select_ticker])\n",
        "  smav_decisioni[select_ticker] = strategy_smav(smav_data = smav_datai[smav_datai['ticker'] == select_ticker])\n",
        "  stochst_decisioni[select_ticker] = strategy_stochst(stochst_data = stochst_datai[stochst_datai['ticker'] == select_ticker])\n",
        "  boband_decisioni[select_ticker] = strategy_boband(boband_data = boband_datai[boband_datai['ticker'] == select_ticker])\n",
        "\n",
        "macd_decisioni = pd.concat(macd_decisioni).reset_index().rename(columns = {'level_0':'ticker'}).set_index('date')\n",
        "boband_decisioni = pd.concat(boband_decisioni).reset_index().rename(columns = {'level_0':'ticker'}).set_index('date')\n",
        "stochst_decisioni = pd.concat(stochst_decisioni).reset_index().rename(columns = {'level_0':'ticker'}).set_index('date')\n",
        "smap_decisioni = pd.concat(smap_decisioni).reset_index().rename(columns = {'level_0':'ticker'}).set_index('date')\n",
        "smav_decisioni = pd.concat(smav_decisioni).reset_index().rename(columns = {'level_0':'ticker'}).set_index('date')\n",
        "\n",
        "#Evaluate investing scenarios\n",
        "invest_table = {}\n",
        "for select_ticker in invest_select:\n",
        "  invest_table[select_ticker] = scenarios_invest(macd_decisioni[macd_decisioni['ticker'] == select_ticker], smap_decisioni[smap_decisioni['ticker'] == select_ticker],\\\n",
        "                                                 smav_decisioni[smav_decisioni['ticker'] == select_ticker], stochst_decisioni[stochst_decisioni['ticker'] == select_ticker],\\\n",
        "                                                 boband_decisioni[boband_decisioni['ticker'] == select_ticker])\n",
        "\n",
        "invest_table = pd.concat(invest_table).reset_index().rename(columns = {'level_0':'ticker'}).set_index('date')\n",
        "\n",
        "########################################################################################################################################################################\n",
        "\n",
        "\n",
        "\n",
        "########################################################BACK TESTING####################################################################################################\n",
        "#Investing\n",
        "HR_return = sum(invest_table['close']*invest_table['HR_signal'])*(-1)            #multiply by -1 so that profit is +ve and loss is -ve\n",
        "MR_return = sum(invest_table['close']*invest_table['MR_signal'])*(-1)\n",
        "LR_return = sum(invest_table['close']*invest_table['LR_signal'])*(-1)\n",
        "\n",
        "\n",
        "backtest_invest = [HR_return, MR_return, LR_return]\n",
        "\n",
        "np.count_nonzero(invest_table['LR_signal']>0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR-W82jS54Qt"
      },
      "source": [
        "def plot_macd(macd_data):\n",
        "\n",
        "  macd_decisions = strategy_macd(macd_data)\n",
        "  buy_price = macd_decisions['buy_price']\n",
        "  sell_price = macd_decisions['sell_price']\n",
        "\n",
        "  ax1 = plt.subplot2grid((8,1), (0,0), rowspan = 5, colspan = 1)\n",
        "  ax2 = plt.subplot2grid((8,1), (5,0), rowspan = 3, colspan = 1)\n",
        "\n",
        "  ax1.plot(macd_data['price'], color = 'skyblue', linewidth = 2, label = str(macd_data['ticker'][1]))\n",
        "  ax1.plot(macd_data.index, buy_price, marker = '^', color = 'green', markersize = 10, label = 'BUY SIGNAL', linewidth = 0)\n",
        "  ax1.plot(macd_data.index, sell_price, marker = 'v', color = 'r', markersize = 10, label = 'SELL SIGNAL', linewidth = 0)\n",
        "  ax1.legend()\n",
        "  ax1.set_title(str(macd_data['ticker'][1]) + ' MACD SIGNALS')\n",
        "  ax2.plot(macd_data['macd'], color = 'grey', linewidth = 1.5, label = 'MACD')\n",
        "  ax2.plot(macd_data['signal'], color = 'skyblue', linewidth = 1.5, label = 'SIGNAL')\n",
        "\n",
        "  for i in range(len(macd_data)):\n",
        "    if macd_data['hist'][i] < 0:\n",
        "      ax2.bar(macd_data.index[i], macd_data['hist'][i], color = '#ef5350')\n",
        "    else:\n",
        "      ax2.bar(macd_data.index[i], macd_data['hist'][i], color = '#26a69a')\n",
        "\n",
        "  plt.legend(loc = 'lower right') \n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxP7W6S3jgw_"
      },
      "source": [
        "def plot_bband(trade_data):\n",
        "#This figure is designed for live trading. Live share price evolution data is supplied at 1 minute intervals.\n",
        "\n",
        "#declare figure\n",
        "  fig = go.Figure()\n",
        "\n",
        "  fig.add_trace(go.Scatter(x=trade_data.index, y= trade_data['Mband'],line=dict(color='blue', width=.7), name = 'Middle Band'))\n",
        "  fig.add_trace(go.Scatter(x=trade_data.index, y= trade_data['Uband'],line=dict(color='red', width=1.5), name = 'Upper Band (Sell)'))\n",
        "  fig.add_trace(go.Scatter(x=trade_data.index, y= trade_data['Lband'],line=dict(color='green', width=1.5), name = 'Lower Band (Buy)'))\n",
        "\n",
        "\n",
        "#Candlestick\n",
        "  fig.add_trace(go.Candlestick(x=trade_data.index,\n",
        "                               open=trade_data['open'],\n",
        "                               high=trade_data['high'],\n",
        "                               low=trade_data['low'],\n",
        "                               close=trade_data['close'], name = 'market data'))\n",
        "\n",
        "# Add titles\n",
        "  fig.update_layout(\n",
        "      title= trade_data['ticker'][1]) + ' live share price evolution',\n",
        "      yaxis_title='Stock Price ($ per share)')\n",
        "\n",
        "# X-Axes\n",
        "  fig.update_xaxes(\n",
        "      rangeslider_visible=True,ç\n",
        "      rangeselector=dict(\n",
        "          buttons=list([\n",
        "                        dict(count=15, label=\"15m\", step=\"minute\", stepmode=\"backward\"),\n",
        "                        dict(count=45, label=\"45m\", step=\"minute\", stepmode=\"backward\"),\n",
        "                        dict(count=1, label=\"HTD\", step=\"hour\", stepmode=\"todate\"),\n",
        "                        dict(count=3, label=\"3h\", step=\"hour\", stepmode=\"backward\"),\n",
        "                        dict(step=\"all\")\n",
        "                        ])\n",
        "          )\n",
        "      )\n",
        "  \n",
        "#Show \n",
        "  fig.show()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzcOFxfJP5KG"
      },
      "source": [
        "# **Unit Testing of Code**\n",
        "\n",
        "Testing components of code\n",
        "Code dumps are located below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8EH446fr_BY"
      },
      "source": [
        "ticker_list = get_ticker_list(grouped_stocks='dow')\n",
        "\n",
        "\n",
        "#trading_datas, *_  = get_historical_data(ticker_list, start_date = \"01/01/2010\", end_date = \"01/01/2021\", index_as_date = True, interval = \"1mo\")\n",
        "trading_datas, _ , _ , _ = get_historical_data(ticker_list=\"AAPL\", start_date = \"05/10/2021\", end_date = \"05/11/2021\", index_as_date = True, interval = \"1d\")\n",
        "trading_datas = yf.download(ticker_list, period = \"1d\", interval = \"60m\", auto_adjust=True)  #check that downloaded table is same format with the table from YahooFinancial library (as against yfinance)\n",
        "trading_datas = get_realtime_data2(ticker_list = ['AAPL', 'CVX'], start=\"2021-05-11\", end=\"2021-05-12\", interval = \"60m\")\n",
        "trading_datas = yf.download(tickers=ticker_list, start=\"2021-05-11\", end=\"2021-05-12\", interval = \"60m\", auto_adjust=True)\n",
        "\n",
        "del trading_datas\n",
        "\n",
        "trading_datas.T\n",
        "\n",
        "tradin_select, invest_select, volatl_select = get_selection(trading_datas)\n",
        "tradin_select\n",
        "invest_select\n",
        "volatl_select\n",
        "\n",
        "macd_data = get_macd(trading_datas, select_ticker = \"AAPL\", fast=6, slow=17, smooth=10)\n",
        "\n",
        "plot_macd(macd_data)\n",
        "\n",
        "current_position = positions_table(macd_data)\n",
        "current_position\n",
        "\n",
        "\n",
        "buy_price, sell_price, macd_signal = strategy_macd(macd_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnKHSWtTW2Gn"
      },
      "source": [
        "def get_historical_data(ticker_list, start_date, end_date, index_as_date, interval):\n",
        "  \n",
        "  trading_datas = {}\n",
        "  \n",
        "  for ticker in ticker_list:\n",
        "    trading_datas[ticker] = si.get_data(ticker, start_date, end_date, index_as_date, interval)  \n",
        "\n",
        "  trading_datas = pd.concat(trading_datas)\n",
        "\n",
        "  return trading_datas  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgxqT-PKHQKZ"
      },
      "source": [
        "def get_realtime_data(ticker_list, period, interval):\n",
        "\n",
        "  trading_datas = {}\n",
        "\n",
        "  for ticker in ticker_list:\n",
        "    trading_datas[ticker] = yf.download(ticker, period, interval)  #check that downloaded table is same format with the table from YahooFinancial library (as against yfinance)\n",
        "\n",
        "  trading_datas = pd.concat(trading_datas)\n",
        "\n",
        "  return trading_datas\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgFM5gfFqw6E"
      },
      "source": [
        "def positions_table(macd_data):\n",
        "\n",
        "  *_ , macd_signal  = strategy_macd(macd_data)\n",
        "\n",
        "  position = []\n",
        "  for i in range(len(macd_signal)):\n",
        "    if macd_signal[i] > 1:\n",
        "      position.append(0)\n",
        "    else:\n",
        "      position.append(1)\n",
        "        \n",
        "  for i in range(len(macd_data['price'])):\n",
        "    if macd_signal[i] == 1:\n",
        "        position[i] = 1\n",
        "    elif macd_signal[i] == -1:\n",
        "        position[i] = 0\n",
        "    else:\n",
        "        position[i] = position[i-1]\n",
        "\n",
        "  macd_signal = pd.DataFrame(macd_signal).rename(columns = {0:'macd_signal'}).set_index(macd_data.index)\n",
        "  position = pd.DataFrame(position).rename(columns = {0:'macd_position'}).set_index(macd_data.index)\n",
        "\n",
        "  position_table = pd.concat([macd_data['price'], macd_data['macd'], macd_data['signal'], macd_signal, position], join = 'inner', axis = 1)\n",
        "  \n",
        "  return position_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uSh3IxjzUPUR",
        "outputId": "bc0cedae-13ca-44c4-8900-a47079b4e05a"
      },
      "source": [
        "\n",
        "start_date = \"01/01/2021\"\n",
        "#end_date=datetime.date.today().isoformat()\n",
        "end_date=datetime.date.today().strftime(\"%d/%m/%y\")  #today\n",
        "end_date=(datetime.date.today() + datetime.timedelta(days=1)).strftime(\"%d/%m/%y\")  #tomorrow\n",
        "\n",
        "end_date=datetime.date.today().strftime(\"%m-%d-%Y\")  #today\n",
        "end_date=(datetime.date.today() + datetime.timedelta(days=1)).strftime(\"%m-%d-%Y\")  #tomorrow\n",
        "\n",
        "end_date=datetime.date.today().strftime(\"%Y-%m-%d\")  #today\n",
        "end_date=(datetime.date.today() + datetime.timedelta(days=-1)).strftime(\"%Y-%m-%d\")  #yesterday\n",
        "\n",
        "df['date'] = pd.to_datetime(df.index).time\n",
        "df.set_index('date', inplace=True)\n",
        "\n",
        "drop(labels=['Adj Close', 'Dividends', 'Stock Splits'], axis=1)\n",
        "\n",
        "df3 = get_smap(trading_datas, select_ticker = \"CVX\", rolling_period=10)\n",
        "\n",
        "plot_macd(df['close'], macd_data['macd'], macd_data['signal'], macd_data['hist'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2021-05-17'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwopaxDWmLxN"
      },
      "source": [
        "dow_list = si.tickers_dow()\n",
        "snp_list = si.tickers_sp500()\n",
        "nas_list = si.tickers_nasdaq()\n",
        "\n",
        "tsx_list = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/tsx_tickers.csv')\n",
        "tsx_list = tsx_list.iloc[:,0].tolist()\n",
        "\n",
        "\n",
        "function ClickConnect(){\n",
        "    console.log(\"Clicked on connect button\"); \n",
        "    document.querySelector(\"colab-connect-button\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5CiGngQ-Ali"
      },
      "source": [
        "ticker_list = dow_list\n",
        "trading_datas = {}\n",
        "cashflow_datas = {}\n",
        "balncsheet_datas = {}\n",
        "incomstment_datas = {}\n",
        "for ticker in ticker_list:\n",
        "    trading_datas[ticker] = si.get_data(ticker, start_date = \"01/01/2001\", end_date = \"01/01/2021\", index_as_date = True, interval = \"1d\")  \n",
        "    cashflow_datas[ticker] = si.get_cash_flow(ticker)  \n",
        "    balncsheet_datas[ticker] = si.get_balance_sheet(ticker)  \n",
        "    incomstment_datas[ticker] = si.get_income_statement(ticker)  \n",
        "\n",
        "trading_datas = pd.concat(trading_datas)\n",
        "cashflow_datas = pd.concat(cashflow_datas)  \n",
        "balncsheet_datas = pd.concat(balncsheet_datas)\n",
        "incomstment_datas = pd.concat(incomstment_datas)\n",
        "\n",
        "cashflow_datas = cashflow_datas.transpose()\n",
        "balncsheet_datas = balncsheet_datas.transpose()\n",
        "incomstment_datas = incomstment_datas.transpose()\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWuO176H-5md"
      },
      "source": [
        "intervals -> 1d, 1wk, 1mo, 3mo, 1yr/1y(?)"
      ]
    }
  ]
}